---
layout: post
title: "Thesis 11: I'm very worried; i feel like i'm drowning"
---
*Monday became rough as the day went on, so I went back and reshaped this entry.*

### The weekend

* I finished *Visual Journalism*
* I looked through *Look Inside*, a book on cutaway illustrations and visual storytelling
* I got distracted on Friday night by an unofficial Maplestory server running an older version of th eMMORPG
* Saturday night I played around with code and [brute-forced some geometric patterns on a 2x2 grid](https://drive.google.com/open?id=1onTATthutM_DhWkgZ8ZvwGjis6mcbFcx). 
* I watched Game of Thrones. 
* I spent \~3 hours debating whether I should learn R and tidyverse or more python packages for data analysis + exploration. (more on this below) 

### Goals for this week

There are 113 days until my defense. My goals for this week are to work on my formula 1 project, prepare a rough outline of my proposal, and confirm my thesis committee (I need to reach out to one more person). I need to find a part-time job while I work on my thesis and later an internship or job that can complement my teaching job in the fall.

### Which tool to learn

On Sunday I was poking around the Formula 1 (F1) data and realized I needed a tool to work with the data's relational format. The last time I worked with relational data was the [National Caseload Data](https://www.justice.gov/usao/resources/foia-library/national-caseload-data) last summer. I spent time writing scripts to turn the txt files into csv files, but when I got to analysis I ended up with some bizarre counting errors when compared to my data editor. I was working with different csvkit commands on the command line.

This time around I thought I'd learn SQL, but in picking between MySQL and PostgreSQL, and then trying to set up the database, I got overwhelemed. Looking at alternatives I saw I could work with the tidyverse or learn a few more python packages (pandas, numpy, matplotlib, and seaborn to start with, but there could be [others](https://activewizards.com/blog/top-20-python-libraries-for-data-science-in-2018/)). I talked to Ali (he suggested python), I talked to Anna (she ended up sending me the link to Renee's website by sharing [therstudio.com](https://therstudio.com) thinking it was related to Rstudio), and I couldn't get a hold of Bjarni on Sunday (but he also suggested python yesterday). I tweeted and asked on the News Nerdery Slack, and two people suggested R. I spent so long trying to decide because it'll influence what I other tools I teach during the data journalism class I have coming up in the fall.

On Sunday I thought R made the most sense, because I could try it out on this single project, and then if I liked it I could probably keep using it. But yesterday I could only get through half of chapter 3 of [#R4DS](https://r4ds.had.co.nz/), and then day went to shit, so I've been reconsidering. I'm worried that I'm trying to pile on too many new things at the same time, and I don't have the time to do it all. **I'm very worried about not finishing.**

### Formula 1

I've started mapping the different tables to see what connects where. In the F1 dataset, we have 3 general categories of data: driver data, constructor data, and race data. And they're all inter related. **Drivers race cars built by constructors to see who is the best over the course of a series of races.** Thinking of what I want to present with this work, I can only envision a summary explorer, but I think analysis will lead me to a better angle. Right now I have data for the first 997 races (1950-2018 seasons), but I want to include the first races of 2019, at least the first 3, to hit the 1000 races mark.  

In thinking about this project, I am inspired by Accurat's work in *La Lettura*. I think their approach to dense data clusters within an overarching architecture is really neat. Maybe the project will turn out in this direction. 

Some aspects of the data I'm interested in are:
* how driver championship standings change over the course of the season (and how that has changed over the many seasons)
* visualizing all the races taking notes of fatalities, how many races per season, race location, race accidents, and which cars didn't finish
* knowing who all the drivers were, when they raced, and what kind of records they set.
* looking at how the set of constructors have changed and who has been the most successful constructor (both overall and if we were to normalise by how long they were in F1)
* Figuring out the best driver, with different best definitions (most championships, podiums, consistency)

My goal going in is to create an explorer of the race data that lets someone new to F1 learn about the sport. I should consult Bjarni on what other aspects he think could be helpful for this. I recently found this list of [F1 fatalities](https://en.wikipedia.org/wiki/List_of_Formula_One_fatalities) and this example of a visual [history of F1](https://www.sportschord.com/formula-1).

There are still so many unknowns in this.

### Today's plan

Keep on learning R using R4DS. While I'm still worried between R and python, I think having the structure of the book will help push me along. I can for example try python way when doing the Amer. Reportage project.